{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>taret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  taret\n",
       "0           5.1          3.5           1.4          0.2      0\n",
       "1           4.9          3.0           1.4          0.2      0\n",
       "2           4.7          3.2           1.3          0.2      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "iris=load_iris()\n",
    "columns =['sepal_length','sepal_width','petal_length','petal_width']\n",
    "irisDF = pd.DataFrame(iris.data, columns= columns)\n",
    "irisDF['taret']=iris.target\n",
    "\n",
    "print(irisDF.shape)\n",
    "irisDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data,iris.target, test_size=0.2,random_state=30)\n",
    "classfier=RandomForestClassifier(random_state=30)\n",
    "classfier.fit(X_train,y_train)\n",
    "pre=classfier.predict(X_test)\n",
    "accuracy_score(y_test,pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08475305, 0.01878451, 0.44890224, 0.4475602 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(irisDF[['petal_length','petal_width']].values,iris.target, test_size=0.2,random_state=30)\n",
    "classfier=RandomForestClassifier(random_state=30)\n",
    "classfier.fit(X_train,y_train)\n",
    "pre=classfier.predict(X_test)\n",
    "accuracy_score(y_test,pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=2)\n",
    "pca.fit(iris.data)\n",
    "pca_data= pca.transform(iris.data)\n",
    "#pca_data\n",
    "#pca.explained_variance_ratio_\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_data,iris.target, test_size=0.2,random_state=30)\n",
    "classfier=RandomForestClassifier(random_state=30)\n",
    "classfier.fit(X_train,y_train)\n",
    "pre=classfier.predict(X_test)\n",
    "accuracy_score(y_test,pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler\n\u001b[0;32m----> 2\u001b[0m cols_bill \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mBILL_AMT\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(\u001b[39m1.7\u001b[39;49m)]\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m대상 속성명:\u001b[39m\u001b[39m'\u001b[39m, cols_bill)\n\u001b[1;32m      5\u001b[0m scaler \u001b[39m=\u001b[39m  StandardScaler()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "cols_bill = ['BILL_AMT' + str(i) for i in range(1.7)]\n",
    "print('대상 속성명:', cols_bill)\n",
    "\n",
    "scaler =  StandardScaler()\n",
    "df_cols_scaled = scaler.fit_transform(X_features[cols_bill])\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(df_cols_scaled)\n",
    "\n",
    "print('PCA Component별 변동성:', pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 여러개의 클러스터링 갯수를 List로 입력 받아 각각의 실루엣 계수를 면적으로 시각화한 함수 작성\n",
    "def visualize_silhouette(cluster_lists, X_features): \n",
    "\n",
    "    from sklearn.datasets import make_blobs\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    import math\n",
    "\n",
    "    # 입력값으로 클러스터링 갯수들을 리스트로 받아서, 각 갯수별로 클러스터링을 적용하고 실루엣 개수를 구함\n",
    "    n_cols = len(cluster_lists)\n",
    "\n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 수만큼의 sub figures를 가지는 axs 생성 \n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "\n",
    "    # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 실루엣 개수 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "\n",
    "        # KMeans 클러스터링 수행하고, 실루엣 스코어와 개별 데이터의 실루엣 값 계산. \n",
    "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
    "        cluster_labels = clusterer.fit_predict(X_features)\n",
    "\n",
    "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "\n",
    "        y_lower = 10\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "                          'Silhouette Score :' + str(round(sil_avg,3)) )\n",
    "        axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
    "        axs[ind].set_ylabel(\"Cluster label\")\n",
    "        axs[ind].set_xlim([-0.1, 1])\n",
    "        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
    "        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        # 클러스터링 갯수별로 fill_betweenx( )형태의 막대 그래프 표현. \n",
    "        for i in range(n_cluster):\n",
    "            ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "            ith_cluster_sil_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "                                facecolor=color, edgecolor=color, alpha=0.7)\n",
    "            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "            y_lower = y_upper + 10\n",
    "\n",
    "        axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터 수 변화시키면서 random 데이터 실루엣 계수 분포 시각화\n",
    "\n",
    "# make_blobs 을 통해 clustering 을 위한 4개의 클러스터 중심의 500개 2차원 데이터 셋 생성  \n",
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(n_samples=500, n_features=2, centers=4, cluster_std=1, \\\n",
    "                  center_box=(-10.0, 10.0), shuffle=True, random_state=1)  \n",
    "\n",
    "# cluster 개수를 2개, 3개, 4개, 5개 일때의 클러스터별 실루엣 계수 평균값을 시각화 \n",
    "visualize_silhouette([ 2, 3, 4, 5], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "visualize_silhouette([2, 3, 4, 5], iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterDF['meanshift_label'] = cluster_labels\n",
    "centers = meanshift.cluster_centers_\n",
    "unique_labels = np.unique(cluster_labels)\n",
    "markers = ['o', 's', '^', 'x', '*']\n",
    "for label in unique_labels:\n",
    "    label_cluster = clusterDF[clusterDF['meanshift_label'] == label]\n",
    "    center_x_y = centers[label]\n",
    "    #군집별로 다른 마커로 산점도 적용\n",
    "    plt.scatter(x=label_cluster['ftr1'], y = label_cluster['ftr2'], edgecolor = 'k', marker = markers[label])\n",
    "    # 군집별 중심 표현\n",
    "    plt.scatter(x = center_x_y[0], y=center_x_y[1], s= 200, color = 'gray', alpha = 0.9, marker = markers[label])\n",
    "    plt.scatter(x = center_x_y[0], y=center_x_y[1], s= 70, color = 'k', edgecolor = 'k', marker = '$%d$' % label)\n",
    "plt.show()\n",
    "print(clusterDF.groupby('target')['meanshift_label'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
